{
        "question": "What is the advantage of using an attention mechanism in RNN-based models for sequence-to-sequence tasks?",
        "type": "many_choice",
        "answers": [
            {
                "answer": "It reduces the number of training samples required",
                "correct": false,
                "feedback": "Try again"
            },
            {
                "answer": "It makes the model less prone to overfitting",
                "correct": false,
                "feedback": "Try again"
            },
            {
                "answer": "It allows the model to focus on relevant parts of the input sequence while generating the output",
                "correct": true,
                "feedback": "Correct."
            },
            {
                "answer": "It speeds up the training process",
                "correct": false,
                "feedback": "Try again"
            
            }]}
        